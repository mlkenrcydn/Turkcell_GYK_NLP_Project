# ğŸ”— Proje Adresi

ğŸ‘‰ GitHub Linki: [https://github.com/mlkenrcydn/Turkcell_GYK_NLP_Project/tree/main/nlp-news-summarization](https://github.com/mlkenrcydn/Turkcell_GYK_NLP_Project/tree/main/nlp-news-summarization)

> Bu proje, T5-Small modelini CNN/DailyMail veri seti ile Ã¶zetler Ã¼retmeyi amaÃ§lamaktadÄ±r.

---

# ğŸ“ T5-Small ile Metin Ã–zetleme Projesi

Bu proje, [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail) veri seti kullanÄ±larak **T5-Small** modeline metin Ã¶zetleme gÃ¶revi iÃ§in **ince ayar (fine-tuning)** yapmayÄ± amaÃ§lamaktadÄ±r.

---

## ğŸ“Œ Projeye Genel BakÄ±ÅŸ

Bu depo, bir metin Ã¶zetleme modeli oluÅŸturmak ve eÄŸitmek iÃ§in gereken tÃ¼m adÄ±mlarÄ± iÃ§ermektedir:

### 1. âœ… Veri YÃ¼kleme ve Ã–n Ä°ÅŸleme
- **CNN/DailyMail** veri seti yÃ¼klenir.
- AÅŸaÄŸÄ±daki iÅŸlemleri yapan Ã¶zel Ã¶n iÅŸleme fonksiyonlarÄ± uygulanÄ±r:
  - HTML etiketlerinin kaldÄ±rÄ±lmasÄ±
  - URL'lerin temizlenmesi
  - Hashtag, Ã¶zel karakter ve fazladan boÅŸluklarÄ±n silinmesi

### 2. ğŸ”¤ Tokenizasyon
- Metin ve Ã¶zetler, **T5-Small tokenizer** ile sayÄ±sal token'lara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.
- Maksimum uzunluk sÄ±ralamalarÄ± auarlanÄ±r.
- Veriler, model giriÅŸi iÃ§in uygun forma getirilir.

### 3. ğŸ§  Model EÄŸitimi
- Hugging Face `transformers` kÃ¼tÃ¼phanesi kullanÄ±larak T5-Small modeli eÄŸitilir.
- EÄŸitim sÃ¼reci, `Seq2SeqTrainer` ile gerÃ§ekleÅŸtirilir.

### 4. ğŸ“Š DeÄŸerlendirme
- Modelin baÅŸarÄ±mÄ±, **ROUGE** metrikleri ile Ã¶lÃ§Ã¼lÃ¼r.
- OluÅŸturulan Ã¶zetler, referans Ã¶zetlerle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.


---

## âš™ï¸ EÄŸitim Parametreleri

`Seq2SeqTrainingArguments` altÄ±nda belirlenen temel parametreler ve aÃ§Ä±klamalarÄ±:

| ArgÃ¼man | AÃ§Ä±klama |
|--------|----------|
| `output_dir="./results"` | Model Ã§Ä±ktÄ±larÄ±nÄ±n kaydedileceÄŸi dizin |
| `per_device_train_batch_size=4` | EÄŸitim sÄ±rasÄ±nda her cihaz iÃ§in batch boyutu |
| `per_device_eval_batch_size=4` | DeÄŸerlendirme sÄ±rasÄ±nda batch boyutu |
| `num_train_epochs=3` | EÄŸitim dÃ¶nemi sayÄ±sÄ± |
| `learning_rate=2e-5` | Ã–ÄŸrenme oranÄ± |
| `logging_dir="./logs"` | Log dosyalarÄ±nÄ±n saklanacaÄŸÄ± dizin |
| `logging_steps=10` | Her 10 adÄ±mda bir log kaydÄ± oluÅŸtur |
| `evaluation_strategy="epoch"` | Her epoch sonunda model deÄŸerlendirmesi yapÄ±lÄ±r |
| `save_strategy="epoch"` | Her epoch sonunda model kaydedilir |
| `report_to="none"` | Harici log aracÄ± kullanÄ±lmaz |
| `predict_with_generate=True` | DeÄŸerlendirme sÄ±rasÄ±nda Ã¶zet Ã¼retimi yapÄ±lÄ±r |
| `load_best_model_at_end=True` | EÄŸitim sonunda en iyi model yÃ¼klenir |
| `metric_for_best_model="rouge1"` | En iyi modeli belirlemek iÃ§in kullanÄ±lan metrik |
| `greater_is_better=True` | Daha yÃ¼ksek `rouge1` puanÄ± daha iyidir |
| `# fp16=torch.cuda.is_available()` | (Ä°steÄŸe baÄŸlÄ±) Mixed precision training iÃ§in Ã¶nerilir |

---

## ğŸ§ª Test Ã–rnekleri

AÅŸaÄŸÄ±da modelin eÄŸitildikten sonra gerÃ§ek haber metinleri Ã¼zerinde Ã¼rettiÄŸi 5 Ã¶rnek ve Ã¶zetleri verilmiÅŸtir:

### Ã–rnek 1
**Girdi Metni:**
> 

**Ãœretilen Ã–zet:**
> 

---

### Ã–rnek 2
**Girdi Metni:**
> 

**Ãœretilen Ã–zet:**
> 

---

### Ã–rnek 3
**Girdi Metni:**
> 

**Ãœretilen Ã–zet:**
> 

---

### Ã–rnek 4
**Girdi Metni:**
> 

**Ãœretilen Ã–zet:**
> 

---

### Ã–rnek 5
**Girdi Metni:**
> 

**Ãœretilen Ã–zet:**
> 

---

## ğŸ“Š ROUGE DeÄŸerlendirme SonuÃ§larÄ±

Modelin test setindeki Ã¶zetleme baÅŸarÄ±mÄ± aÅŸaÄŸÄ±daki gibidir:

| Metrik | Skor |
|--------|------|
| **ROUGE-1** | `` |
| **ROUGE-2** | `` |
| **ROUGE-L** | `` |

> ROUGE-1 ve ROUGE-L skorlarÄ±nÄ±n yÃ¼ksekliÄŸi, modelin anlam bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ olan Ã¶zetler Ã¼retebildiÄŸini gÃ¶stermektedir.

---

## âœ… SonuÃ§



---

